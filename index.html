<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MLSP Project Page</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
</head>

<body>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-2/js/all.min.js'> </script>
  
  <section class="hero is-dark is-light is-small">
    <div class="hero-body">
      <div class="container">
            <h1 class="title is-2 has-text-centered">Voice Conversion</h1>
            <h2 class="subtitle is-5 has-text-centered">MLSP Project, Istanbul Technical University<br>Fall 2020</h2> 
            <h3 class="subtitle is-5 has-text-centered">Selahaddin HONİ &nbsp|&nbsp İsmail Melik TÜRKER &nbsp|&nbsp İmran Çağla EYÜBOĞLU</h3> 
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <h1 class="title is-5" style="text-align: left;">Project Aim</h1>
      </div>
    </div>
  </section>
  <section>
    <div class="container">
      <br><p>
        In the project, it is aimed to transfer the trained voice style of a famous person to given input voice. 
        Follow the links for 
        <a href="static/paper/vc-cycle-gan-report.pdf" target="_blank">final report</a> 
        and
        <a href="static/paper/vc-cycle-gan-presentation.pdf" target="_blank">brief presentation</a>.<br> 
      </p><br>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <h1 class="title is-5" style="text-align: left;">Reference Paper & Implementation</h1>
      </div>
    </div>
  </section>
  <section>
  <section>
    <div class="container">
      <br><p>
        <a href="static/paper/CycleGAN-VC-1711.11293.pdf" target="_blank">[Paper link]</a><br>   
        Takuhiro Kaneko and Hirokazu Kameoka<br>
        <strong>Parallel-Data-Free Voice Conversion Using Cycle-Consistent Adversarial Networks</strong><br>
        <br>
        <a href="https://github.com/leimao/Voice-Converter-CycleGAN" target="_blank">[Implementation link]</a><br>   
        Lei Mao's work<br>
        <strong>Voice Converter Using CycleGAN and Non-Parallel Data</strong><br>
        <br>
        <a href="https://github.com/001honi/vc-cycle-gan" target="_blank">[Project]</a><br>   
        Our Work<br>
        <strong>MLSP Term Project: Voice Conversion</strong>
      </p><br>
    </div>
  </section>
   

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <h1 class="title is-5" style="text-align: left;">Dataset</h1>
      </div>
    </div>
  </section>
  <section>
    <div class="container">
      <br><p>
        <strong>Source</strong><br>
        Google's text-to-speech voices are used to generate 13 audio clips (each in a duration of approx. 40 secs) in a total of at least 8 minutes for each speaker. <br>
        <u>Female Speaker</u> <em>WaveNet Turkish Female voice G</em><br>
        <u>Male Speaker</u> <em>WaveNet Turkish Male voice E</em><br>
        <br><strong>Target</strong><br>
        Similarly, 13 audio clips in a total duration of 8.8 minutes of Turkish news-presenter Ece Uner's speech is chosen.
        <hr>
        The dataset link is <a href="https://drive.google.com/drive/folders/1bdSAbpLWZiw6tz3zrpNq2OhFxhPdLyhI?usp=sharing" target="_blank">here</a>.  
      </p><br>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <h1 class="title is-5" style="text-align: left;">Result</h1>
      </div>
    </div>
  </section>
  <section>
    <div class="container">
        <br><p>        
          <strong>Training Samples</strong> 
          <br>Below speech samples are given into the model in training phase. There is no parallelism between source and target.
        </p>
        <br>

        <table class="table" style="margin-left:auto;margin-right:auto;">
          <thead>
            <tr>
              <th style="text-align: center;">Source (Female)</th>
              <th style="text-align: center;">Source (Male)</th>
              <th style="text-align: center;">Target (Female)</th>
            </tr>
          </thead>
          <tbody>
          <tr>
            <td><audio controls><source src="static/audio/TR-F-GGL-D-11.mp3" type="audio/mpeg"></audio></td>
            <td><audio controls><source src="static/audio/TR-M-GGL-E-11.mp3" type="audio/mpeg"></audio></td>
            <td><audio controls><source src="static/audio/TR-F-ECE-11.mp3" type="audio/mpeg"></audio></td>
           </tr>
        </tbody>
      </table>
      <hr>
      <p>        
        <strong>Validation Samples</strong> 
        <br>In the first row of table, original record of source speech is placed.
        <br>Remaining rows are the outputs of #-epochs trained models for given input.
      </p>
      <br>
      <table class="table" style="margin-left:auto;margin-right:auto;">
        <thead>
          <tr>
            <th></th>
            <th style="text-align: center;">CycleGAN-VC (Female-to-Female)</th>
            <th style="text-align: center;">CycleGAN-VC (Male-to-Female)</th>
          </tr>
        </thead>
        <tbody>
        <tr>
          <th style="vertical-align: middle;">Input</th>
          <td><audio controls><source src="static/audio/TR-F-GGL-D-TEST-00.mp3" type="audio/mpeg"></audio></td>
          <td><audio controls><source src="static/audio/TR-M-GGL-E-TEST-00.mp3" type="audio/mpeg"></audio></td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">500 Epochs</th>
          <td><audio controls><source src="static/audio/TR-F-GGL-D-TEST-00-CONV- 500-EPOCH.wav" type="audio/mpeg"></audio></td>
          <td><audio controls><source src="static/audio/TR-M-GGL-E-TEST-00-CONV- 500-EPOCH.wav" type="audio/mpeg"></audio></td>
        <tr>
          <th style="vertical-align: middle;">1500 Epochs</th>
          <td><audio controls><source src="static/audio/TR-F-GGL-D-TEST-00-CONV-1500-EPOCH.wav" type="audio/mpeg"></audio></td>
          <td><audio controls><source src="static/audio/TR-M-GGL-E-TEST-00-CONV-1500-EPOCH.wav" type="audio/mpeg"></audio></td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">5000 Epochs</th>
          <td><audio controls><source src="static/audio/TR-F-GGL-D-TEST-00-CONV-5000-EPOCH.wav" type="audio/mpeg"></audio></td>
          <td><audio controls><source src="static/audio/TR-M-GGL-E-TEST-00-CONV-5000-EPOCH.wav" type="audio/mpeg"></audio></td>
        </tr>
      </tbody>
    </table>
    <p>
      <u>Input</u><em> "Merhaba, bu ses CycleGAN ile üretildi." (Hi, this voice is generated by CycleGAN)</em><br>
      *Of course, the input speech is not generated by this network; however 'the outputs' are.
    </p>
    <hr>
    <p>
      There are 3 more examples in <a href="https://drive.google.com/drive/folders/1bdSAbpLWZiw6tz3zrpNq2OhFxhPdLyhI?usp=sharing" target="_blank">this</a> folder.<br>
    </p><br>
    
    </div>
  </section>
 
  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        January, 2021
      </p>
    </div>
  </footer>

</body>
</html>
